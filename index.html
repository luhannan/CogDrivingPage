<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>CogDriving</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Seeing Beyond Views: Multi-View Driving Scene Video Generation with Holistic Attention</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="" target="_blank">Hannan Lu</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Xiaohe Wu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Shudong Wang</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Xiameng Qin</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Xinyu Zhang</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Junyu han</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Wangmeng Zuo</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Ji Tao</a><sup>2</sup>,
              </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>Harbin Institute of Technology,</span>
                <span class="author-block"><sup>2</sup>Changan Automobile,</span>
                <span class="author-block"><sup>3</sup>The University of Adelaide</span>
                <!-- <span class="eql-cntrb"><small><br>(<sup>*</sup>Co-first authors. <sup>†</sup>Corresponding
                    Author)</small></span> -->
              </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- <h2 class="title is-3">Another Carousel</h2> -->
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="videos/vid1/reshape/idx18293_view0_rank4.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="videos/vid1/reshape/idx69_view0_rank0.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="videos/vid1/reshape/idx183_view0_rank0.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="video4" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="videos/vid1/reshape/idx1817_view0_rank0.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video5">
          <video poster="" id="video5" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="videos/vid1/reshape/idx5295_view0_rank1.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating multi-view videos for autonomous driving training has recently gained attention, with the challenge of addressing both cross-view and cross-frame consistency.
            Existing methods typically apply decoupled attention mechanisms for spatial, temporal, and view dimensions.
            However, these approaches often struggle to maintain consistency across dimensions, particularly when handling fast-moving objects that appear at different times and viewpoints.
            In this paper, we present CogDriving, a novel network designed for synthesizing high-quality multi-view driving videos. 
            CogDriving leverages a Diffusion Transformer architecture with holistic-4D attention modules, enabling simultaneous associations across the spatial, temporal, and viewpoint dimensions.
            We also propose a lightweight controller tailored for CogDriving, i.e., Micro-Controller, which uses only 1.1% of the parameters of the standard ControlNet, enabling precise control over Bird’s-Eye-View layouts.
            To enhance the generation of object instances crucial for autonomous driving, we propose a re-weighted learning objective, dynamically adjusting the learning weights for object instances during training.
            CogDriving demonstrates strong performance on the nuScenes validation set, achieving an FVD score of 37.8, highlighting its ability to generate realistic driving videos.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title">Diffusion transformer with holistic 4D-Attention</h2>
        <div class="content">
          <img src="figs/overview.png" alt="Recovering the Pre-Fine-Tuning Weight of an Aligned Mistral 7B" class="blend-img-background center-image">
          <div class="level-set has-text-justified">
            <p>
              Overview of our CogDriving. 
              (a) depicts the training process of CogDriving, facilitated by the diffusion transformer with holistic 4D-Attention. 
              (b) illustrates the detailed architecture of the diffusion transformer, especially the holistic 4D-Attention to achieve the spatial-temporal-perspective mutual interaction. 
              (c) shows the proposed Micro-Controller for the integration of various conditions.</p>
          </div>
        </div>
        
      </div>
    </div>
  </div>
</section>


<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title">BEV layouts controlled generation</h2>
        <div class="content">
          <img src="figs/fig1_3.png" alt="Recovering the Pre-Fine-Tuning Weight of an Aligned Mistral 7B" class="blend-img-background center-image">
          <div class="level-set has-text-justified">
            <p>
              Our lightweight Micro-Controller encodes road maps, box IDs, class IDs, and depth maps independently from 3D annotations for precise, geometry-guided synthesis.
            </p>
          </div>
        </div>
        
      </div>
    </div>
  </div>
</section>

<!-- <section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title">Attribute control using text description</h2>
        <div class="content">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="videos/weather2_2.mp4"
            type="video/mp4">
          </video>
          <div class="level-set has-text-justified">
          </div>
        </div>
        
      </div>
    </div>
  </div>
</section> -->



<!-- Video carousel -->
<section class="hero is-small is-four-fifths">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Attribute control using text description</h2>
      <!-- <h2 class="title is-3">Another Carousel</h2> -->
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="videos/weather_3.mp4"
            type="video/mp4">
          </video>
        </div>

        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="videos/season_1.mp4"
            type="video/mp4">
          </video>
        </div>

        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="videos/time_1.mp4"
            type="video/mp4">
          </video>
        </div>
        
      </div>

      <div class="content">
        <div class="level-set has-text-justified">
          <p>
            CogDriving can generates diverse driving videos, including different weather, seasons, times, even extreme scenarios such as thunderstorms.
          </p>
        </div>
      </div>

    </div>
  </div>
</section>
<!-- End video carousel -->



  
<!-- <section class="section hero is-light"></section>
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">BEV layouts controlled generation</h2>
        <div class="content has-text-justified">
          <img src="figs/fig1_3.png" alt="Recovering the Pre-Fine-Tuning Weight of an Aligned Mistral 7B" class="blend-img-background center-image">
          <p>
            Our lightweight Micro-Controller encodes road maps, box IDs, class IDs, and depth maps independently from 3D annotations for precise, geometry-guided synthesis.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
             <!-- which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. -->
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
